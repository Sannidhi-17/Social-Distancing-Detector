{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorcycle',\n",
       " 'airplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'couch',\n",
       " 'potted plant',\n",
       " 'bed',\n",
       " 'dining table',\n",
       " 'toilet',\n",
       " 'tv',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsPath = \"./coco.names\"\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102, 220, 225],\n",
       "       [ 95, 179,  61],\n",
       "       [234, 203,  92],\n",
       "       [  3,  98, 243],\n",
       "       [ 14, 149, 245],\n",
       "       [ 46, 106, 244],\n",
       "       [ 99, 187,  71],\n",
       "       [212, 153, 199],\n",
       "       [188, 174,  65],\n",
       "       [153,  20,  44],\n",
       "       [203, 152, 102],\n",
       "       [214, 240,  39],\n",
       "       [121,  24,  34],\n",
       "       [114, 210,  65],\n",
       "       [239,  39, 214],\n",
       "       [244, 151,  25],\n",
       "       [ 74, 145, 222],\n",
       "       [ 14, 202,  85],\n",
       "       [145, 117,  87],\n",
       "       [184, 189, 221],\n",
       "       [116, 237, 109],\n",
       "       [ 85,  99, 172],\n",
       "       [226, 153, 103],\n",
       "       [235, 146,  36],\n",
       "       [151,  62,  68],\n",
       "       [181, 130, 160],\n",
       "       [160, 166, 149],\n",
       "       [  6,  69,   5],\n",
       "       [ 52, 253, 112],\n",
       "       [ 14,   1,   3],\n",
       "       [ 76, 248,  87],\n",
       "       [233, 212, 184],\n",
       "       [235, 245,  26],\n",
       "       [213, 157, 253],\n",
       "       [ 68, 240,  37],\n",
       "       [219,  91,  54],\n",
       "       [129,   9,  51],\n",
       "       [  0, 191,  20],\n",
       "       [140,  46, 187],\n",
       "       [147,   1, 254],\n",
       "       [ 20, 153, 243],\n",
       "       [ 46, 160,  68],\n",
       "       [ 19, 158, 203],\n",
       "       [209, 226,  77],\n",
       "       [ 57,  77, 149],\n",
       "       [156,  21, 112],\n",
       "       [ 86, 134, 252],\n",
       "       [ 24, 207,   1],\n",
       "       [235, 242, 147],\n",
       "       [110,  88, 107],\n",
       "       [231,   5,  48],\n",
       "       [254, 141,  74],\n",
       "       [218, 161,  87],\n",
       "       [134,  58, 100],\n",
       "       [162, 156, 254],\n",
       "       [ 73,  93, 102],\n",
       "       [169, 222, 181],\n",
       "       [ 35,  71, 242],\n",
       "       [ 11, 219, 253],\n",
       "       [201,  74, 187],\n",
       "       [ 10,  72, 249],\n",
       "       [207, 227, 201],\n",
       "       [ 93,  14, 231],\n",
       "       [150,  59, 189],\n",
       "       [  0, 193, 116],\n",
       "       [189, 251,  49],\n",
       "       [ 23, 174,  74],\n",
       "       [  1, 201, 189],\n",
       "       [139,  78, 158],\n",
       "       [ 50, 210,  29],\n",
       "       [ 51, 107,   7],\n",
       "       [233,  97,  54],\n",
       "       [222, 164, 131],\n",
       "       [243,   4, 181],\n",
       "       [251,  63, 123],\n",
       "       [168, 151, 248],\n",
       "       [197, 125, 119],\n",
       "       [130,  44, 228],\n",
       "       [ 11, 228,  13],\n",
       "       [ 37, 220,  50]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size = (len(LABELS), 3), dtype = 'uint8')\n",
    "COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 000002583A265630>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsPath = \"./yolov3.weights\"\n",
    "configPath = \"./yolov3.cfg\"\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Prediction Time : 0.886630 seconds\n",
      "Frame Prediction Time : 0.899594 seconds\n",
      "Frame Prediction Time : 0.818812 seconds\n",
      "Frame Prediction Time : 0.822796 seconds\n",
      "Frame Prediction Time : 0.854713 seconds\n",
      "Frame Prediction Time : 0.864688 seconds\n",
      "Frame Prediction Time : 0.883625 seconds\n",
      "Frame Prediction Time : 0.881636 seconds\n",
      "Frame Prediction Time : 0.851701 seconds\n",
      "Frame Prediction Time : 0.832762 seconds\n",
      "Frame Prediction Time : 0.855715 seconds\n",
      "Frame Prediction Time : 0.899595 seconds\n",
      "Frame Prediction Time : 1.048191 seconds\n",
      "Frame Prediction Time : 0.952444 seconds\n",
      "Frame Prediction Time : 0.959435 seconds\n",
      "Frame Prediction Time : 0.837758 seconds\n",
      "Frame Prediction Time : 0.837758 seconds\n",
      "Frame Prediction Time : 0.860699 seconds\n",
      "Frame Prediction Time : 0.852716 seconds\n",
      "Frame Prediction Time : 0.795872 seconds\n",
      "[0, 1]\n",
      "Frame Prediction Time : 2.200116 seconds\n",
      "Frame Prediction Time : 0.824785 seconds\n",
      "Frame Prediction Time : 1.783228 seconds\n",
      "Frame Prediction Time : 1.610696 seconds\n",
      "Frame Prediction Time : 0.881643 seconds\n",
      "Frame Prediction Time : 1.050189 seconds\n",
      "Frame Prediction Time : 0.985366 seconds\n",
      "Frame Prediction Time : 0.796866 seconds\n",
      "Frame Prediction Time : 2.191140 seconds\n",
      "Frame Prediction Time : 0.818812 seconds\n",
      "Frame Prediction Time : 2.208095 seconds\n",
      "Frame Prediction Time : 0.849720 seconds\n",
      "Frame Prediction Time : 2.216065 seconds\n",
      "Frame Prediction Time : 0.817812 seconds\n",
      "Frame Prediction Time : 0.869663 seconds\n",
      "Frame Prediction Time : 1.024267 seconds\n",
      "Frame Prediction Time : 1.723382 seconds\n",
      "Frame Prediction Time : 2.380630 seconds\n",
      "Frame Prediction Time : 1.012284 seconds\n",
      "Frame Prediction Time : 0.872666 seconds\n",
      "Frame Prediction Time : 2.237017 seconds\n",
      "Frame Prediction Time : 0.817815 seconds\n",
      "Frame Prediction Time : 2.209092 seconds\n",
      "Frame Prediction Time : 0.817817 seconds\n",
      "Frame Prediction Time : 2.179170 seconds\n",
      "Frame Prediction Time : 0.879650 seconds\n",
      "Frame Prediction Time : 2.412552 seconds\n",
      "Frame Prediction Time : 2.398580 seconds\n",
      "Frame Prediction Time : 0.833766 seconds\n",
      "Frame Prediction Time : 2.227047 seconds\n",
      "Frame Prediction Time : 0.804844 seconds\n",
      "Frame Prediction Time : 2.181162 seconds\n",
      "Frame Prediction Time : 0.803848 seconds\n",
      "Frame Prediction Time : 2.194135 seconds\n",
      "Frame Prediction Time : 0.812794 seconds\n",
      "Frame Prediction Time : 2.354702 seconds\n",
      "Frame Prediction Time : 2.346720 seconds\n",
      "Frame Prediction Time : 0.971400 seconds\n",
      "Frame Prediction Time : 2.218069 seconds\n",
      "Frame Prediction Time : 0.892607 seconds\n",
      "Frame Prediction Time : 2.260947 seconds\n",
      "Frame Prediction Time : 0.861696 seconds\n",
      "Frame Prediction Time : 2.083421 seconds\n",
      "Frame Prediction Time : 2.258957 seconds\n",
      "Frame Prediction Time : 1.080112 seconds\n",
      "Frame Prediction Time : 2.555164 seconds\n",
      "Frame Prediction Time : 2.326778 seconds\n",
      "Frame Prediction Time : 0.808838 seconds\n",
      "Frame Prediction Time : 2.197140 seconds\n",
      "Frame Prediction Time : 0.825794 seconds\n",
      "Frame Prediction Time : 2.245994 seconds\n",
      "Frame Prediction Time : 0.803849 seconds\n",
      "Frame Prediction Time : 2.232030 seconds\n",
      "Frame Prediction Time : 0.994335 seconds\n",
      "Frame Prediction Time : 1.666537 seconds\n",
      "Frame Prediction Time : 2.349739 seconds\n",
      "Frame Prediction Time : 0.830775 seconds\n",
      "Frame Prediction Time : 2.316806 seconds\n",
      "[0, 1]\n",
      "Frame Prediction Time : 0.847735 seconds\n",
      "[0, 1]\n",
      "Frame Prediction Time : 2.199121 seconds\n",
      "Frame Prediction Time : 0.820806 seconds\n",
      "Frame Prediction Time : 1.756288 seconds\n",
      "Frame Prediction Time : 2.295864 seconds\n",
      "Frame Prediction Time : 0.987359 seconds\n",
      "Frame Prediction Time : 2.378655 seconds\n",
      "Frame Prediction Time : 0.834763 seconds\n",
      "Frame Prediction Time : 2.205100 seconds\n",
      "Frame Prediction Time : 1.184843 seconds\n",
      "Frame Prediction Time : 1.297516 seconds\n",
      "Frame Prediction Time : 2.204113 seconds\n",
      "Frame Prediction Time : 0.812809 seconds\n",
      "Frame Prediction Time : 2.234028 seconds\n",
      "Frame Prediction Time : 1.006319 seconds\n",
      "Frame Prediction Time : 2.525245 seconds\n",
      "Frame Prediction Time : 2.438476 seconds\n",
      "Frame Prediction Time : 0.875660 seconds\n",
      "[0, 1]\n",
      "Frame Prediction Time : 2.221055 seconds\n",
      "Frame Prediction Time : 0.825790 seconds\n",
      "Frame Prediction Time : 2.207098 seconds\n",
      "Frame Prediction Time : 0.827785 seconds\n",
      "Frame Prediction Time : 2.455446 seconds\n",
      "Frame Prediction Time : 2.354701 seconds\n",
      "Frame Prediction Time : 1.139950 seconds\n",
      "Frame Prediction Time : 1.872974 seconds\n",
      "Frame Prediction Time : 2.756628 seconds\n",
      "Frame Prediction Time : 2.357696 seconds\n",
      "Frame Prediction Time : 0.867676 seconds\n",
      "Frame Prediction Time : 2.351710 seconds\n",
      "Frame Prediction Time : 2.395592 seconds\n",
      "Frame Prediction Time : 0.990350 seconds\n",
      "Frame Prediction Time : 2.362682 seconds\n",
      "Frame Prediction Time : 1.495016 seconds\n",
      "Frame Prediction Time : 1.008293 seconds\n",
      "Frame Prediction Time : 2.232042 seconds\n",
      "Frame Prediction Time : 0.817813 seconds\n",
      "Frame Prediction Time : 2.231028 seconds\n",
      "Frame Prediction Time : 0.852718 seconds\n",
      "Frame Prediction Time : 2.574115 seconds\n",
      "Frame Prediction Time : 2.650909 seconds\n",
      "Frame Prediction Time : 2.619974 seconds\n",
      "Frame Prediction Time : 0.920537 seconds\n",
      "[0, 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-11e4de951276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mlayerOutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mln\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Frame Prediction Time : {:.6f} seconds\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    (H, W) = image.shape[:2]\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416,416), swapRB = True, crop = False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward(ln)   \n",
    "    end = time.time()\n",
    "    print(\"Frame Prediction Time : {:.6f} seconds\".format(end - start))\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > 0.1 and classID == 0:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                \n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,0.3)\n",
    "    ind = []\n",
    "    for i in range(0, len(classIDs)):\n",
    "        if(classIDs[i] == 0):\n",
    "            ind.append(i)\n",
    "            \n",
    "    a = []\n",
    "    b = []\n",
    "\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            a.append(x)\n",
    "            b.append(y)\n",
    "    \n",
    "    distance = []\n",
    "    nsd = []\n",
    "\n",
    "    for i in range(0, len(a) - 1):\n",
    "        for k in range(1, len(a)):\n",
    "            if(k == i):\n",
    "                break\n",
    "            else:\n",
    "                x_dist = (a[k] - a[i])\n",
    "                y_dist = (b[k] - b[i])\n",
    "            \n",
    "                d = math.sqrt(x_dist * x_dist + y_dist * y_dist)\n",
    "                distance.append(d)\n",
    "            \n",
    "                if(d <= 100):\n",
    "                    nsd.append(i)\n",
    "                    nsd.append(k)\n",
    "                    nsd = list(dict.fromkeys(nsd))\n",
    "                    print(nsd)\n",
    "                    \n",
    "    color = (0, 0, 255)\n",
    "    for i in nsd:\n",
    "        (x, y) = (boxes[i][0], boxes[i][1])\n",
    "        (w, h) = (boxes[i][2], boxes[i][3])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        text = \"Alert\"\n",
    "        cv2.putText(image, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "    color = (0, 255, 0)\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            if (i in nsd):\n",
    "                break\n",
    "            else:\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "                text = 'OK'\n",
    "                cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)\n",
    "                \n",
    "    cv2.imshow(\"Social Distancing Detector\", image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindowa()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
